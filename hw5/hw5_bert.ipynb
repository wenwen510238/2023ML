{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"50dbae4c6c0e48048fb57384497d2c21":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e8113373cea4bccb7dc8c4cdbad0c3e","IPY_MODEL_27d13eceebf341f5846cd0004e0d0c3c","IPY_MODEL_d6198e73c25c457c8c1911ee0b4d9da1"],"layout":"IPY_MODEL_b64c1468c60849809f19d71854ca0d86"}},"4e8113373cea4bccb7dc8c4cdbad0c3e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c3f8e11715743b68a2c1122ba23061f","placeholder":"​","style":"IPY_MODEL_139502554817435e82c545f86f65dae7","value":"100%"}},"27d13eceebf341f5846cd0004e0d0c3c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_379ed7648711497095eb904546d8bbb0","max":1621,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c899d2970264afba5876612ddb53e24","value":1621}},"d6198e73c25c457c8c1911ee0b4d9da1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0745e6e46b9a47fd95120741a2a5a0c5","placeholder":"​","style":"IPY_MODEL_b33cdb8b54814323b161eca42bffaba3","value":" 1621/1621 [14:58&lt;00:00,  1.78it/s]"}},"b64c1468c60849809f19d71854ca0d86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c3f8e11715743b68a2c1122ba23061f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"139502554817435e82c545f86f65dae7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"379ed7648711497095eb904546d8bbb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c899d2970264afba5876612ddb53e24":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0745e6e46b9a47fd95120741a2a5a0c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b33cdb8b54814323b161eca42bffaba3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95dedc329c4f42118ee715e273288287":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f1026247ed2c4aceb5557f95c3c82d92","IPY_MODEL_badfeaa4671a4b0eb25dab1707dcf2ae","IPY_MODEL_d730e1290c114a9eb4fdb9cce743f95f"],"layout":"IPY_MODEL_e728ba7e424e4e11809002af12c8fd0b"}},"f1026247ed2c4aceb5557f95c3c82d92":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64deee0775964c1b821d1a4df82c6932","placeholder":"​","style":"IPY_MODEL_b4fae4512c59437299c382ffb4df3365","value":"100%"}},"badfeaa4671a4b0eb25dab1707dcf2ae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5233f839ff8e4538bc5a27277a44fdab","max":3524,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8010161dfd7d4a069f5a8f621aede222","value":3524}},"d730e1290c114a9eb4fdb9cce743f95f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5afbacb367674b638988fecef03aff2d","placeholder":"​","style":"IPY_MODEL_1ee7a19356ee494a93478cf3609b35ca","value":" 3524/3524 [10:32&lt;00:00,  6.08it/s]"}},"e728ba7e424e4e11809002af12c8fd0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64deee0775964c1b821d1a4df82c6932":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4fae4512c59437299c382ffb4df3365":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5233f839ff8e4538bc5a27277a44fdab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8010161dfd7d4a069f5a8f621aede222":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5afbacb367674b638988fecef03aff2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ee7a19356ee494a93478cf3609b35ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48a4febb4f064e2f9b001e2c1e8f3476":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a94bab9dda794548877b1e4dc27a649b","IPY_MODEL_27f2c770c42a4055809985163814c050","IPY_MODEL_5bf152923ca343afb59cb25497c05923"],"layout":"IPY_MODEL_e6a5b7f4d4704848b236cc9ac084508a"}},"a94bab9dda794548877b1e4dc27a649b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3ab6570b5254d4b99a2f03b15606121","placeholder":"​","style":"IPY_MODEL_ff1b128143624036a101a2812fb79f5e","value":"100%"}},"27f2c770c42a4055809985163814c050":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2e8da9442bf43b2b27a54c2793b8154","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_49f99f436d0842b1acda571a1368d144","value":1000}},"5bf152923ca343afb59cb25497c05923":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a4a8c54d38d4accadd02ee20118ff6a","placeholder":"​","style":"IPY_MODEL_679fca52c074469ca3155b7ccb486b2c","value":" 1000/1000 [02:49&lt;00:00,  6.91it/s]"}},"e6a5b7f4d4704848b236cc9ac084508a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3ab6570b5254d4b99a2f03b15606121":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff1b128143624036a101a2812fb79f5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2e8da9442bf43b2b27a54c2793b8154":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49f99f436d0842b1acda571a1368d144":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1a4a8c54d38d4accadd02ee20118ff6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"679fca52c074469ca3155b7ccb486b2c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"xvSGDbExff_I"},"source":["# **Homework 7 - Bert (Question Answering)**\n","\n","If you have any questions, feel free to email us at kafuchino0410@gmail.com\n","\n","\n","\n","Kaggle: [Link](https://www.kaggle.com/competitions/ntpucsie-ml2022spring-hw5)　Data: [Link](https://drive.google.com/file/d/1u1OjLJLf2kPRJicGSgnBwiWPOtl6eaN6/view?usp=sharing)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"WGOr_eS3wJJf"},"source":["## Task description\n","- Chinese Extractive Question Answering\n","  - Input: Paragraph + Question\n","  - Output: Answer\n","\n","- Objective: Learn how to fine tune a pretrained model on downstream task using transformers\n","\n","- Todo\n","    - Fine tune a pretrained chinese BERT model\n","    - Change hyperparameters (e.g. doc_stride)\n","    - Apply linear learning rate decay\n","    - Try other pretrained models\n","    - Improve preprocessing\n","    - Improve postprocessing\n","- Training tips\n","    - Automatic mixed precision\n","    - Gradient accumulation\n","    - Ensemble\n","\n","- Estimated training time (tesla t4 with automatic mixed precision enabled)\n","    - Simple: 8mins\n","    - Medium: 8mins\n","    - Strong: 25mins\n","    - Boss: 2hrs\n","  "]},{"cell_type":"markdown","metadata":{"id":"TJ1fSAJE2oaC"},"source":["## Download Dataset"]},{"cell_type":"code","metadata":{"id":"YPrc4Eie9Yo5","executionInfo":{"status":"ok","timestamp":1684161547190,"user_tz":-480,"elapsed":2,"user":{"displayName":"溫佩旻","userId":"04733238697345043038"}}},"source":["# # Download link 1\n","# !gdown --id '1u1OjLJLf2kPRJicGSgnBwiWPOtl6eaN6' --output hw7_data.zip\n","\n","# !unzip -o hw7_data.zip\n","\n","# # For this HW, K80 < P4 < T4 < P100 <= T4(fp16) < V100\n","# !nvidia-smi"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TevOvhC03m0h"},"source":["## Install transformers\n","\n","Documentation for the toolkit:　https://huggingface.co/transformers/"]},{"cell_type":"code","metadata":{"id":"tbxWFX_jpDom","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2b3bf364-7c27-4201-a4c6-a6a0649c7f6b","executionInfo":{"status":"ok","timestamp":1684161559297,"user_tz":-480,"elapsed":11031,"user":{"displayName":"溫佩旻","userId":"04733238697345043038"}}},"source":["# You are allowed to change version of transformers or use other toolkits\n","# !pip install transformers==4.5.0\n","!pip install transformers==4.26.1\n","!pip install accelerate==0.16.0"],"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers==4.26.1 in /usr/local/lib/python3.10/dist-packages (4.26.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1) (3.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1) (0.14.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.1) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.1) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.26.1) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.26.1) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.26.1) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.26.1) (3.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: accelerate==0.16.0 in /usr/local/lib/python3.10/dist-packages (0.16.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.16.0) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.16.0) (23.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.16.0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.16.0) (6.0)\n","Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.16.0) (2.0.0+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate==0.16.0) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate==0.16.0) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate==0.16.0) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate==0.16.0) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate==0.16.0) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate==0.16.0) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate==0.16.0) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate==0.16.0) (16.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->accelerate==0.16.0) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->accelerate==0.16.0) (1.3.0)\n"]}]},{"cell_type":"markdown","metadata":{"id":"8dKM4yCh4LI_"},"source":["## Import Packages"]},{"cell_type":"code","metadata":{"id":"WOTHHtWJoahe","executionInfo":{"status":"ok","timestamp":1684161559297,"user_tz":-480,"elapsed":3,"user":{"displayName":"溫佩旻","userId":"04733238697345043038"}}},"source":["import json\n","import numpy as np\n","import random\n","import torch\n","from torch.utils.data import DataLoader, Dataset \n","from transformers import AdamW, BertForQuestionAnswering, BertTokenizerFast\n","\n","from tqdm.auto import tqdm\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Fix random seed for reproducibility\n","def same_seeds(seed):\n","\ttorch.manual_seed(seed)\n","\tif torch.cuda.is_available():\n","\t\ttorch.cuda.manual_seed(seed)\n","\t\ttorch.cuda.manual_seed_all(seed)\n","\tnp.random.seed(seed)\n","\trandom.seed(seed)\n","\ttorch.backends.cudnn.benchmark = False\n","\ttorch.backends.cudnn.deterministic = True\n","same_seeds(0)"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"7pBtSZP1SKQO","executionInfo":{"status":"ok","timestamp":1684161559298,"user_tz":-480,"elapsed":3,"user":{"displayName":"溫佩旻","userId":"04733238697345043038"}}},"source":["# Change \"fp16_training\" to True to support automatic mixed precision training (fp16)\t\n","fp16_training = False\n","\n","if fp16_training:\n","    !pip install accelerate==0.2.0\n","    from accelerate import Accelerator\n","    accelerator = Accelerator(fp16=True)\n","    device = accelerator.device\n","\n","# Documentation for the toolkit:  https://huggingface.co/docs/accelerate/"],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2YgXHuVLp_6j"},"source":["## Load Model and Tokenizer\n","\n","\n","\n","\n"," "]},{"cell_type":"code","metadata":{"id":"xyBCYGjAp3ym","executionInfo":{"status":"ok","timestamp":1684161560342,"user_tz":-480,"elapsed":1047,"user":{"displayName":"溫佩旻","userId":"04733238697345043038"}}},"source":["from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"NchuNLP/Chinese-Question-Answering\")\n","\n","model = AutoModelForQuestionAnswering.from_pretrained(\"NchuNLP/Chinese-Question-Answering\").to(device)\n","\n","# model_name = \"luhua/chinese_pretrain_mrc_roberta_wwm_ext_large\"\n","# # model = BertForQuestionAnswering.from_pretrained(\"bert-base-chinese\").to(device)\n","# model = BertForQuestionAnswering.from_pretrained(model_name).to(device)\n","# tokenizer = BertTokenizerFast.from_pretrained(model_name)\n","\n","# You can safely ignore the warning message (it pops up because new prediction heads for QA are initialized randomly)"],"execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Td-GTmk5OW4"},"source":["## Read Data\n","\n","- Training set: 26935 QA pairs\n","- Dev set: 3523  QA pairs\n","- Test set: 3492  QA pairs\n","\n","- {train/dev/test}_questions:\t\n","  - List of dicts with the following keys:\n","   - id (int)\n","   - paragraph_id (int)\n","   - question_text (string)\n","   - answer_text (string)\n","   - answer_start (int)\n","   - answer_end (int)\n","- {train/dev/test}_paragraphs: \n","  - List of strings\n","  - paragraph_ids in questions correspond to indexs in paragraphs\n","  - A paragraph may be used by several questions "]},{"cell_type":"code","metadata":{"id":"NvX7hlepogvu","executionInfo":{"status":"ok","timestamp":1684161561361,"user_tz":-480,"elapsed":1021,"user":{"displayName":"溫佩旻","userId":"04733238697345043038"}}},"source":["def read_data(file):\n","    with open(file, 'r', encoding=\"utf-8\") as reader:\n","        data = json.load(reader)\n","    return data[\"questions\"], data[\"paragraphs\"]\n","\n","train_questions, train_paragraphs = read_data(\"hw7_train.json\")\n","dev_questions, dev_paragraphs = read_data(\"hw7_dev.json\")\n","test_questions, test_paragraphs = read_data(\"hw7_test.json\")"],"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fm0rpTHq0e4N"},"source":["## Tokenize Data"]},{"cell_type":"code","metadata":{"id":"rTZ6B70Hoxie","executionInfo":{"status":"ok","timestamp":1684161582504,"user_tz":-480,"elapsed":21146,"user":{"displayName":"溫佩旻","userId":"04733238697345043038"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3a4753f6-35a9-4699-9603-2c879a7b2e90"},"source":["# Tokenize questions and paragraphs separately\n","# 「add_special_tokens」 is set to False since special tokens will be added when tokenized questions and paragraphs are combined in datset __getitem__ \n","\n","train_questions_tokenized = tokenizer([train_question[\"question_text\"] for train_question in train_questions], add_special_tokens=False)\n","dev_questions_tokenized = tokenizer([dev_question[\"question_text\"] for dev_question in dev_questions], add_special_tokens=False)\n","test_questions_tokenized = tokenizer([test_question[\"question_text\"] for test_question in test_questions], add_special_tokens=False) \n","\n","train_paragraphs_tokenized = tokenizer(train_paragraphs, add_special_tokens=False)\n","dev_paragraphs_tokenized = tokenizer(dev_paragraphs, add_special_tokens=False)\n","test_paragraphs_tokenized = tokenizer(test_paragraphs, add_special_tokens=False)\n","\n","# You can safely ignore the warning message as tokenized sequences will be futher processed in datset __getitem__ before passing to model"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n"]}]},{"cell_type":"markdown","metadata":{"id":"Ws8c8_4d5UCI"},"source":["## Dataset and Dataloader"]},{"cell_type":"code","metadata":{"id":"Xjooag-Swnuh","executionInfo":{"status":"ok","timestamp":1684161582504,"user_tz":-480,"elapsed":14,"user":{"displayName":"溫佩旻","userId":"04733238697345043038"}}},"source":["class QA_Dataset(Dataset):\n","    def __init__(self, split, questions, tokenized_questions, tokenized_paragraphs):\n","        self.split = split\n","        self.questions = questions\n","        self.tokenized_questions = tokenized_questions\n","        self.tokenized_paragraphs = tokenized_paragraphs\n","        self.max_question_len = 40\n","        self.max_paragraph_len = 150\n","        # self.max_paragraph_len = 300\n","        \n","        ##### TODO: Change value of doc_stride #####\n","        self.doc_stride = 32\n","        # self.doc_stride = 200\n","        # self.doc_stride = 150\n","\n","        # Input sequence length = [CLS] + question + [SEP] + paragraph + [SEP]\n","        self.max_seq_len = 1 + self.max_question_len + 1 + self.max_paragraph_len + 1\n","\n","    def __len__(self):\n","        return len(self.questions)\n","\n","    def __getitem__(self, idx):\n","        question = self.questions[idx]\n","        tokenized_question = self.tokenized_questions[idx]\n","        tokenized_paragraph = self.tokenized_paragraphs[question[\"paragraph_id\"]]\n","\n","        ##### TODO: Preprocessing #####\n","        # Hint: How to prevent model from learning something it should not learn\n","\n","        if self.split == \"train\":\n","            # Convert answer's start/end positions in paragraph_text to start/end positions in tokenized_paragraph  \n","            answer_start_token = tokenized_paragraph.char_to_token(question[\"answer_start\"])\n","            answer_end_token = tokenized_paragraph.char_to_token(question[\"answer_end\"])\n","\n","            # A single window is obtained by slicing the portion of paragraph containing the answer\n","            # mid = (answer_start_token + answer_end_token) // 2\n","            # paragraph_start = max(0, min(mid - self.max_paragraph_len // 2, len(tokenized_paragraph) - self.max_paragraph_len))\n","            start_min = max(0, answer_end_token - self.max_paragraph_len+1)\n","            start_max= min(answer_start_token, len(tokenized_paragraph)-self.max_paragraph_len)\n","            start_max = max(start_min, start_max)\n","            paragraph_start = random.randint(start_min, start_max+1)\n","            paragraph_end = paragraph_start + self.max_paragraph_len\n","            \n","            # Slice question/paragraph and add special tokens (101: CLS, 102: SEP)\n","            input_ids_question = [101] + tokenized_question.ids[:self.max_question_len] + [102] \n","            input_ids_paragraph = tokenized_paragraph.ids[paragraph_start : paragraph_end] + [102]\t\t\n","            \n","            # Convert answer's start/end positions in tokenized_paragraph to start/end positions in the window  \n","            answer_start_token += len(input_ids_question) - paragraph_start\n","            answer_end_token += len(input_ids_question) - paragraph_start\n","            \n","            # Pad sequence and obtain inputs to model \n","            input_ids, token_type_ids, attention_mask = self.padding(input_ids_question, input_ids_paragraph)\n","            return torch.tensor(input_ids), torch.tensor(token_type_ids), torch.tensor(attention_mask), answer_start_token, answer_end_token\n","\n","        # Validation/Testing\n","        else:\n","            input_ids_list, token_type_ids_list, attention_mask_list = [], [], []\n","            \n","            # Paragraph is split into several windows, each with start positions separated by step \"doc_stride\"\n","            for i in range(0, len(tokenized_paragraph), self.doc_stride):\n","                \n","                # Slice question/paragraph and add special tokens (101: CLS, 102: SEP)\n","                input_ids_question = [101] + tokenized_question.ids[:self.max_question_len] + [102]\n","                input_ids_paragraph = tokenized_paragraph.ids[i : i + self.max_paragraph_len] + [102]\n","                \n","                # Pad sequence and obtain inputs to model\n","                input_ids, token_type_ids, attention_mask = self.padding(input_ids_question, input_ids_paragraph)\n","                \n","                input_ids_list.append(input_ids)\n","                token_type_ids_list.append(token_type_ids)\n","                attention_mask_list.append(attention_mask)\n","            \n","            return torch.tensor(input_ids_list), torch.tensor(token_type_ids_list), torch.tensor(attention_mask_list)\n","\n","    def padding(self, input_ids_question, input_ids_paragraph):\n","        # Pad zeros if sequence length is shorter than max_seq_len\n","        padding_len = self.max_seq_len - len(input_ids_question) - len(input_ids_paragraph)\n","        # Indices of input sequence tokens in the vocabulary\n","        input_ids = input_ids_question + input_ids_paragraph + [0] * padding_len\n","        # Segment token indices to indicate first and second portions of the inputs. Indices are selected in [0, 1]\n","        token_type_ids = [0] * len(input_ids_question) + [1] * len(input_ids_paragraph) + [0] * padding_len\n","        # Mask to avoid performing attention on padding token indices. Mask values selected in [0, 1]\n","        attention_mask = [1] * (len(input_ids_question) + len(input_ids_paragraph)) + [0] * padding_len\n","        \n","        return input_ids, token_type_ids, attention_mask\n","\n","train_set = QA_Dataset(\"train\", train_questions, train_questions_tokenized, train_paragraphs_tokenized)\n","dev_set = QA_Dataset(\"dev\", dev_questions, dev_questions_tokenized, dev_paragraphs_tokenized)\n","test_set = QA_Dataset(\"test\", test_questions, test_questions_tokenized, test_paragraphs_tokenized)\n","\n","train_batch_size = 16\n","\n","# Note: Do NOT change batch size of dev_loader / test_loader !\n","# Although batch size=1, it is actually a batch consisting of several windows from the same QA pair\n","train_loader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True, pin_memory=True)\n","dev_loader = DataLoader(dev_set, batch_size=1, shuffle=False, pin_memory=True)\n","test_loader = DataLoader(test_set, batch_size=1, shuffle=False, pin_memory=True)"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5_H1kqhR8CdM"},"source":["## Function for Evaluation"]},{"cell_type":"code","metadata":{"id":"SqeA3PLPxOHu","executionInfo":{"status":"ok","timestamp":1684161582504,"user_tz":-480,"elapsed":13,"user":{"displayName":"溫佩旻","userId":"04733238697345043038"}}},"source":["def evaluate(data, output):\n","    ##### TODO: Postprocessing #####\n","    # There is a bug and room for improvement in postprocessing \n","    # Hint: Open your prediction file to see what is wrong \n","    \n","    answer = ''\n","    max_prob = float('-inf')\n","    num_of_windows = data[0].shape[1]\n","    \n","    for k in range(num_of_windows):\n","        # Obtain answer by choosing the most probable start position / end position\n","        start_prob, start_index = torch.max(output.start_logits[k], dim=0)\n","        end_prob, end_index = torch.max(output.end_logits[k], dim=0)\n","        if start_index > end_index:\n","          continue\n","        \n","        # Probability of answer is calculated as sum of start_prob and end_prob\n","        prob = start_prob + end_prob\n","        \n","        # Replace answer if calculated probability is larger than previous windows\n","        if prob > max_prob:\n","            max_prob = prob\n","            # Convert tokens to chars (e.g. [1920, 7032] --> \"大 金\")\n","            answer = tokenizer.decode(data[0][0][k][start_index : end_index + 1])\n","    \n","    # Remove spaces in answer (e.g. \"大 金\" --> \"大金\")\n","    return answer.replace(' ','')"],"execution_count":41,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rzHQit6eMnKG"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"3Q-B6ka7xoCM","executionInfo":{"status":"ok","timestamp":1684163118965,"user_tz":-480,"elapsed":1536473,"user":{"displayName":"溫佩旻","userId":"04733238697345043038"}},"colab":{"base_uri":"https://localhost:8080/","height":428,"referenced_widgets":["50dbae4c6c0e48048fb57384497d2c21","4e8113373cea4bccb7dc8c4cdbad0c3e","27d13eceebf341f5846cd0004e0d0c3c","d6198e73c25c457c8c1911ee0b4d9da1","b64c1468c60849809f19d71854ca0d86","7c3f8e11715743b68a2c1122ba23061f","139502554817435e82c545f86f65dae7","379ed7648711497095eb904546d8bbb0","8c899d2970264afba5876612ddb53e24","0745e6e46b9a47fd95120741a2a5a0c5","b33cdb8b54814323b161eca42bffaba3","95dedc329c4f42118ee715e273288287","f1026247ed2c4aceb5557f95c3c82d92","badfeaa4671a4b0eb25dab1707dcf2ae","d730e1290c114a9eb4fdb9cce743f95f","e728ba7e424e4e11809002af12c8fd0b","64deee0775964c1b821d1a4df82c6932","b4fae4512c59437299c382ffb4df3365","5233f839ff8e4538bc5a27277a44fdab","8010161dfd7d4a069f5a8f621aede222","5afbacb367674b638988fecef03aff2d","1ee7a19356ee494a93478cf3609b35ca"]},"outputId":"5b55b943-d6f7-4042-9f30-4ff3d3a6227e"},"source":["from transformers import get_linear_schedule_with_warmup\n","num_epoch = 1 \n","validation = True\n","logging_step = 100\n","learning_rate = 1e-4\n","acc_steps = 4\n","optimizer = AdamW(model.parameters(), lr=learning_rate)\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=1000)\n","\n","if fp16_training:\n","    model, optimizer, train_loader = accelerator.prepare(model, optimizer, train_loader) \n","\n","model.train()\n","\n","print(\"Start Training ...\")\n","\n","for epoch in range(num_epoch):\n","    step = 1\n","    train_loss = train_acc = 0\n","    \n","    for data in tqdm(train_loader):\t\n","        # Load all data into GPU\n","        data = [i.to(device) for i in data]\n","        \n","        # Model inputs: input_ids, token_type_ids, attention_mask, start_positions, end_positions (Note: only \"input_ids\" is mandatory)\n","        # Model outputs: start_logits, end_logits, loss (return when start_positions/end_positions are provided)  \n","        output = model(input_ids=data[0], token_type_ids=data[1], attention_mask=data[2], start_positions=data[3], end_positions=data[4])\n","\n","        # Choose the most probable start position / end position\n","        start_index = torch.argmax(output.start_logits, dim=1)\n","        end_index = torch.argmax(output.end_logits, dim=1)\n","        \n","        # Prediction is correct only if both start_index and end_index are correct\n","        train_acc += ((start_index == data[3]) & (end_index == data[4])).float().mean()\n","        train_loss += output.loss\n","        \n","        if fp16_training:\n","            accelerator.backward(output.loss)\n","        else:\n","            output.loss.backward()\n","        \n","        if step % acc_steps == 0:\n","          optimizer.step()\n","          optimizer.zero_grad()\n","          #每次運算完後啟動scheduler\n","          scheduler.step()\n","        step += 1\n","\n","        ##### TODO: Apply linear learning rate decay #####\n","        \n","        # Print training loss and accuracy over past logging step\n","        if step % logging_step == 0:\n","            print(f\"Epoch {epoch + 1} | Step {step} | loss = {train_loss.item() / logging_step:.3f}, acc = {train_acc / logging_step:.3f}\")\n","            train_loss = train_acc = 0\n","\n","    if validation:\n","        print(\"Evaluating Dev Set ...\")\n","        model.eval()\n","        with torch.no_grad():\n","            dev_acc = 0\n","            for i, data in enumerate(tqdm(dev_loader)):\n","                output = model(input_ids=data[0].squeeze(dim=0).to(device), token_type_ids=data[1].squeeze(dim=0).to(device),\n","                       attention_mask=data[2].squeeze(dim=0).to(device))\n","                # prediction is correct only if answer text exactly matches\n","                dev_acc += evaluate(data, output) == dev_questions[i][\"answer_text\"]\n","            print(f\"Validation | Epoch {epoch + 1} | acc = {dev_acc / len(dev_loader):.3f}\")\n","        model.train()\n","\n","# Save a model and its configuration file to the directory 「saved_model」 \n","# i.e. there are two files under the direcory 「saved_model」: 「pytorch_model.bin」 and 「config.json」\n","# Saved model can be re-loaded using 「model = BertForQuestionAnswering.from_pretrained(\"saved_model\")」\n","print(\"Saving Model ...\")\n","model_save_dir = \"saved_model\" \n","model.save_pretrained(model_save_dir)"],"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Start Training ...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1621 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50dbae4c6c0e48048fb57384497d2c21"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 | Step 100 | loss = 1.399, acc = 0.841\n","Epoch 1 | Step 200 | loss = 0.313, acc = 0.882\n","Epoch 1 | Step 300 | loss = 0.203, acc = 0.909\n","Epoch 1 | Step 400 | loss = 0.205, acc = 0.903\n","Epoch 1 | Step 500 | loss = 0.179, acc = 0.913\n","Epoch 1 | Step 600 | loss = 0.187, acc = 0.902\n","Epoch 1 | Step 700 | loss = 0.180, acc = 0.907\n","Epoch 1 | Step 800 | loss = 0.190, acc = 0.911\n","Epoch 1 | Step 900 | loss = 0.168, acc = 0.916\n","Epoch 1 | Step 1000 | loss = 0.177, acc = 0.907\n","Epoch 1 | Step 1100 | loss = 0.166, acc = 0.906\n","Epoch 1 | Step 1200 | loss = 0.190, acc = 0.901\n","Epoch 1 | Step 1300 | loss = 0.146, acc = 0.922\n","Epoch 1 | Step 1400 | loss = 0.192, acc = 0.904\n","Epoch 1 | Step 1500 | loss = 0.148, acc = 0.926\n","Epoch 1 | Step 1600 | loss = 0.185, acc = 0.918\n","Evaluating Dev Set ...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3524 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95dedc329c4f42118ee715e273288287"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Validation | Epoch 1 | acc = 0.775\n","Saving Model ...\n"]}]},{"cell_type":"markdown","metadata":{"id":"kMmdLOKBMsdE"},"source":["## Testing"]},{"cell_type":"code","metadata":{"id":"U5scNKC9xz0C","executionInfo":{"status":"ok","timestamp":1684163288492,"user_tz":-480,"elapsed":169539,"user":{"displayName":"溫佩旻","userId":"04733238697345043038"}},"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["48a4febb4f064e2f9b001e2c1e8f3476","a94bab9dda794548877b1e4dc27a649b","27f2c770c42a4055809985163814c050","5bf152923ca343afb59cb25497c05923","e6a5b7f4d4704848b236cc9ac084508a","c3ab6570b5254d4b99a2f03b15606121","ff1b128143624036a101a2812fb79f5e","c2e8da9442bf43b2b27a54c2793b8154","49f99f436d0842b1acda571a1368d144","1a4a8c54d38d4accadd02ee20118ff6a","679fca52c074469ca3155b7ccb486b2c"]},"outputId":"84531725-24f7-456e-adba-327e05c871bd"},"source":["print(\"Evaluating Test Set ...\")\n","\n","result = []\n","\n","model.eval()\n","with torch.no_grad():\n","    for data in tqdm(test_loader):\n","        output = model(input_ids=data[0].squeeze(dim=0).to(device), token_type_ids=data[1].squeeze(dim=0).to(device),\n","                       attention_mask=data[2].squeeze(dim=0).to(device))\n","        result.append(evaluate(data, output))\n","\n","result_file = \"result.csv\"\n","with open(result_file, 'w') as f:\t\n","  f.write(\"ID,Answer\\n\")\n","  for i, test_question in enumerate(test_questions):\n","    # Replace commas in answers with empty strings (since csv is separated by comma)\n","    # Answers in kaggle are processed in the same way\n","    f.write(f\"{test_question['id']},{result[i].replace(',','')}\\n\")\n","\n","print(f\"Completed! Result is in {result_file}\")"],"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluating Test Set ...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48a4febb4f064e2f9b001e2c1e8f3476"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Completed! Result is in result.csv\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"dPMFMBVb5egT","executionInfo":{"status":"ok","timestamp":1684163288492,"user_tz":-480,"elapsed":13,"user":{"displayName":"溫佩旻","userId":"04733238697345043038"}}},"execution_count":43,"outputs":[]}]}